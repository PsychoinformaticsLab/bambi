{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Models\n",
    "\n",
    "Survival models, also known as time-to-event models, are specialized statistical methods designed to analyze the time until the occurrence of an event of interest. In this notebook, a review of survival analysis  and censored data is provided, followed by a survival model implementation in Bambi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival and censoring times\n",
    "\n",
    "Sometimes the right way to model discrete, countable events is to model not the counts themselves but rather the **time between events**. This gives us information regarding the rate of an event. Survival models are models for countable things, but the outcomes we want to predict are durations. Durations are continuous deviations from some point of reference (so they are all positive values). \n",
    "\n",
    "The tricky part with survival models is not the probability distribution assigned to the durations, but dealing with censoring. Censoring occurs when the event of interest does not occur in the window of observation. In a simple scenario, this can happen because the observation period ends before the event occurred. Censored individuas (or units) can not just be dropped from the sample. Imagine a cohort of 100 cats who start waiting for adoption at the same time. After one month, half of them have been adopted. Now what is the rate of adoption? You can’t compute it using only the cats who have been adopted. You need to also account for the cats who haven’t yet been adopted. The cats who haven’t been adopted yet, but eventually will be adopted, clearly have longer waiting times than the cats who have already been adopted. So the average rate among those who are already adopted is biased upwards—it is confounded by conditioning on adoption.\n",
    "\n",
    "Including censored observations requires a new type of model. The key idea is that the same distribution assumption for the outcome tells us both the probability of any observed duration that end in the event as well as the probability that we would wait the observed duration without seeing the event. For each unit, we assume there is a true _survival time_ $T$ as well as a true censoring time $C$. The survival time represents the time at which the event of interest occurs. The censoring time is the time at which censoring occurs. We observe either: the survival, or the censoring time:\n",
    "\n",
    "$$Y = \\text{min}(T, C)$$\n",
    "\n",
    "If the event occurs, then we observe the survival time, else we observe the censoring time. In order to analyze survival data, we first need to understand the two types of censoring: left and right censoring, and how to estimate the survival function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left and right censoring\n",
    "\n",
    "There are two main \"types\" of censoring: right and left. Right sensoring occurs when $T \\ge Y$, i.e. the true event time $T$ is at least as large as the observed time $Y$. This is a consequence of $Y = \\text{min}(T, C)$. Right censoring derives its name from the notion that time is typically read and displayed from left to right. Left sensoring occurs when the true event time $T$ is less than or equal to the observed time $Y$. An example of left censoring could be in a study of pregnancy duration, suppose that patients are surveyed 250 days (8.2 months) after conception. Some patients may have already had their babies. For these patients, pregnancy duration is **less than** 250 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the survival function\n",
    "\n",
    "Survival analysis is concerned with estimating the survival function $S(t)$\n",
    "\n",
    "$$S(t) = Pr(T > t) = 1 - F(t)$$\n",
    "\n",
    "which is a decreasing function that quantifies the probability of surviving past time $t$. Alternatively, $S(t)$ can be expressed as one minus the cumulative distribution function (CDF) $F$ of the event time $T$—referred to as the complementary cumulative distribution function (CCDF). The focus on the survival function is important because for censored observations, we only know that the time-to-event exceeds the observed time $Y$.\n",
    "\n",
    "Here, continuing with the cat adoption example, we consider the task of estimating the survival function for cat adoptions. To estimate $S(30) = Pr(T > 30)$, the probability that a cat is not adopted after 30 days, it is tempting to compute the proportion of cats who were adopted before 30 days and subtract this from 1. However, this would be incorrect because it ignores the cats who were not adopted before 30 days but who **will be** adopted later—these cats clearly have longer adoption rates. Thus, if we continued with the naive approach, the average rate of adoption would be biased upwards—it is confounded by conditioning on adoption.\n",
    "\n",
    "However, it is possible to overcome this challenge by using the Kaplan-Meier estimator. The Kaplan-Meier estimator is a non-parametric estimator of the survival function that accounts for censoring. Let $d_1 < d_2 < . . . < d_K$ denote the $K$ unique adoption times among the non-censored cats, and $q_k$ denote the number of cats adopted at time $d_k$. For $k = 1,...,K$, let $r_k$ denote the number of cats not adopted at time $d_k$. By the law of total probability\n",
    "\n",
    "$$Pr(T > d_k) = Pr(T > d_k | T > d_{k-1}) Pr(T > d_{k-1}) + Pr(T > d_k | T \\leq d_{k-1}) Pr(T \\leq d_{k-1})$$\n",
    "\n",
    "The fact that $d_{k-1} < d_k$ implies that $Pr(T > d_k | T \\leq d_{k-1}) = 0$ (as it is impossible for a cat to be adopted past time $d_k$ if the cat was adopted before time $d_{k-1}$). Thus, if we simplify the above equation and plug into the survival function, we obtain\n",
    "\n",
    "$$S(d_k) = Pr(T > d_k | T > d_{k-1})S(d_{k-1})$$\n",
    "\n",
    "Now we must estimate the terms on the right-hand side. It is common to use the following estimator \n",
    "\n",
    "$$\\hat{Pr}(T > d_j | T > d_{j-1}) = \\frac{r_j - q_j}{r_j}$$\n",
    "\n",
    "which leads us to the Kaplan-Meier estimator of the survival function\n",
    "\n",
    "$$\\hat{S}(d_k) = \\prod_{j=1}^k \\frac{r_j - q_j}{r_j}$$\n",
    "\n",
    "Below is a Python function implementing the Kaplan-Meier estimator to estimate the survival function for cat adoptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import scipy\n",
    "\n",
    "import bambi as bmb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/AustinCats.csv\"\n",
    "cats = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "cats_new = cats.copy()\n",
    "cats_new[\"adopt\"] = np.where(cats_new[\"out_event\"] == \"Adoption\", \"right\", \"none\")\n",
    "cats_new[\"color_id\"] = np.where(cats_new[\"color\"] == \"Black\", 1, 0)\n",
    "cats_new = cats_new[[\"days_to_event\", \"adopt\", \"color_id\"]]\n",
    "\n",
    "cats_sample = cats_new.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3))\n",
    "plt.hist(cats_new[\"days_to_event\"], bins=250, label=\"Uncensored data\")\n",
    "plt.xlim(0, 150) # truncate for visibility\n",
    "plt.title(\"Days Until Adoption\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I AM NOT SURE THIS IS GIVING THE CORRECT ESTIMATES\n",
    "def kaplan_meier_estimator(d_k, d, times):\n",
    "    \"\"\"\n",
    "    Compute the Kaplan-Meier estimator.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - d_k: np.ndarray\n",
    "        Array of unique observed event times.\n",
    "    - d: np.ndarray\n",
    "        Array indicating if the event occurred at the time from the 'd_k' list;\n",
    "        True if event occurred, False if censored.\n",
    "    - times: np.ndarray\n",
    "        Array of times at which the survival function should be evaluated.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    - List of Kaplan-Meier estimates at the specified 'times'.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(d_k)\n",
    "    survival = []\n",
    "    s_prev = 1\n",
    "\n",
    "    for time in times:\n",
    "        product = s_prev\n",
    "        for i in range(n):\n",
    "            if d_k[i] <= time:\n",
    "                product *= (1 - d[i] / (n - i))\n",
    "        survival.append(product)\n",
    "        s_prev = product\n",
    "\n",
    "    return survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_adoption_times = cats_new[cats_new[\"adopt\"] == \"right\"][\"days_to_event\"].values\n",
    "adoption = (cats_new[\"adopt\"] == \"right\").values\n",
    "evaluation_times = np.arange(0, 30, 1)\n",
    "adoption_km_estimates = kaplan_meier_estimator(\n",
    "    observed_adoption_times, adoption, evaluation_times\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.step(evaluation_times, adoption_km_estimates, where=\"post\", label=\"Kaplan-Meier Estimate\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Cat Adoption Probability\")\n",
    "plt.title(\"Probability of a Cat Not Being Adopted by time $d_k$\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models with a survival response\n",
    "\n",
    "It is often the case that we would like to understand how various predictors are associated with the survival function. For example, we may want to know if the survival function for cats of different colors or species is different. As outlined above, we cannot simply run a regression on the observed times $Y$ given some predictors $X$. What we are actually interested in is predicting the survival time $T$ given the predictors $X$. To achieve this, Bambi utilizes the [censored distribution](https://www.pymc.io/projects/docs/en/latest/api/distributions/censored.html) from PyMC which allows us to make use of a sequential construction, similar to the Kaplan-Meier estimator outlined above. To understand how the censored distribution allows us to fit regression models with survival responses, we first need to understand the Hazard function and the Cox proportional hazards model.\n",
    "\n",
    "### The Hazard function\n",
    "\n",
    "The hazard function is defined as the instantaneous rate of an event occuring at time $t$ given that the event has not yet occured. The hazard function is defined as\n",
    "\n",
    "$$h(t) = \\lim_{\\Delta t \\rightarrow 0} \\frac{Pr(t \\leq T < t + \\Delta t | T \\geq t)}{\\Delta t}$$\n",
    "\n",
    "where $T$ is the (unobserved) survival time. The Hazard function is closely related to the survival function $S(t)$, and it is a key approach for modeling survival data as a function of predictors. However, it is typical to phrase the model in terms of the cumulative hazard function\n",
    "\n",
    "$$\\Lambda(t) = -\\text{log} S(t)$$\n",
    "\n",
    "\n",
    "### The Cox proportional hazards model\n",
    "\n",
    "Above, we used the Kaplan-Meier estimator to estimate the survival function for cat adoptions. However, since we would now like to add predictor(s), a risk regression model is more appropriate. \n",
    "\n",
    "### The censored distribution\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation in Bambi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat adoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabestechschulte/miniforge3/envs/bambinos/lib/python3.11/site-packages/formulae/terms/variable.py:87: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_string_dtype(x) or is_categorical_dtype(x):\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.5 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"306pt\" height=\"276pt\"\n",
       " viewBox=\"0.00 0.00 306.00 275.63\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 271.63)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-271.63 302,-271.63 302,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>clustercolor_id_dim (2)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-137.82C107,-137.82 192,-137.82 192,-137.82 198,-137.82 204,-143.82 204,-149.82 204,-149.82 204,-247.63 204,-247.63 204,-253.63 198,-259.63 192,-259.63 192,-259.63 107,-259.63 107,-259.63 101,-259.63 95,-253.63 95,-247.63 95,-247.63 95,-149.82 95,-149.82 95,-143.82 101,-137.82 107,-137.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-145.02\" font-family=\"Times,serif\" font-size=\"14.00\">color_id_dim (2)</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>clustercensored(days_to_event, adopt)_obs (22356)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M20,-8C20,-8 278,-8 278,-8 284,-8 290,-14 290,-20 290,-20 290,-117.82 290,-117.82 290,-123.82 284,-129.82 278,-129.82 278,-129.82 20,-129.82 20,-129.82 14,-129.82 8,-123.82 8,-117.82 8,-117.82 8,-20 8,-20 8,-14 14,-8 20,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"159.75\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"14.00\">censored(days_to_event, adopt)_obs (22356)</text>\n",
       "</g>\n",
       "<!-- color_id -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>color_id</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-210.98\" rx=\"43.13\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"149\" y=\"-222.43\" font-family=\"Times,serif\" font-size=\"14.00\">color_id</text>\n",
       "<text text-anchor=\"middle\" x=\"149\" y=\"-205.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"149\" y=\"-189.43\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- censored(days_to_event, adopt) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>censored(days_to_event, adopt)</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"149\" cy=\"-81.16\" rx=\"133.29\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"149\" y=\"-92.61\" font-family=\"Times,serif\" font-size=\"14.00\">censored(days_to_event, adopt)</text>\n",
       "<text text-anchor=\"middle\" x=\"149\" y=\"-76.11\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"149\" y=\"-59.61\" font-family=\"Times,serif\" font-size=\"14.00\">Censored</text>\n",
       "</g>\n",
       "<!-- color_id&#45;&gt;censored(days_to_event, adopt) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>color_id&#45;&gt;censored(days_to_event, adopt)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149,-169.88C149,-158.23 149,-145.33 149,-133.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-133.11 149,-123.11 145.5,-133.11 152.5,-133.11\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x16bbd0210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model = bmb.Model(\n",
    "    \"censored(days_to_event, adopt) ~ 0 + color_id\", \n",
    "    data=cats_new,\n",
    "    center_predictors=False,\n",
    "    categorical=[\"color_id\"],\n",
    "    family=\"exponential\",\n",
    "    link=\"log\"\n",
    ")\n",
    "cat_model.build()\n",
    "cat_model.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = cat_model.fit(tune=500, draws=500, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model.predict(idata, kind=\"mean\")\n",
    "cat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC implementation\n",
    "\n",
    "Stan code:\n",
    "\n",
    "\n",
    "```R\n",
    "library(rethinking)\n",
    "data(AustinCats)\n",
    "\n",
    "d <- AustinCats\n",
    "d$adopt <- ifelse( d$out_event==\"Adoption\" , 1L , 0L )\n",
    "dat <- list(\n",
    "    days_to_event = as.numeric( d$days_to_event ),\n",
    "    color_id = ifelse( d$color==\"Black\" , 1L , 2L ) ,\n",
    "    adopted = d$adopt\n",
    ")\n",
    "m11.15 <- ulam(\n",
    "    alist(\n",
    "        days_to_event|adopted==1 ~ exponential( lambda ),\n",
    "        days_to_event|adopted==0 ~ custom(exponential_lccdf( !Y | lambda )),\n",
    "        lambda <- 1.0/mu,\n",
    "        log(mu) <- a[color_id],\n",
    "        a[color_id] ~ normal(0,1)\n",
    "    ), data=dat , chains=4 , cores=4 )\n",
    "\n",
    "precis( m11.15 , 2 )\n",
    "```\n",
    "```shell\n",
    "     mean   sd 5.5% 94.5% n_eff Rhat\n",
    "a[1] 4.05 0.03 4.01  4.09  1405    1\n",
    "a[2] 3.88 0.01 3.87  3.90  1403    1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = cat_model.response_component.design\n",
    "\n",
    "x = dm.common.design_matrix[:, 1]\n",
    "observed = np.squeeze(dm.response.design_matrix[:, 0])\n",
    "censoring_code = np.squeeze(dm.response.design_matrix[:, 1])\n",
    "\n",
    "is_left_censored = censoring_code == -1\n",
    "is_right_censored = censoring_code == 1\n",
    "\n",
    "lower = np.where(is_left_censored, observed, -np.inf)\n",
    "upper = np.where(is_right_censored, observed, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cats_new.reset_index(drop=True).copy()\n",
    "d[\"adopt\"] = np.where(d[\"adopt\"] == \"right\", 1, 0)\n",
    "\n",
    "dat = {\n",
    "    'days_to_event': d['days_to_event'].values.astype(np.int64),\n",
    "    'color_id': d['color_id'].values.astype(np.int64),\n",
    "    'adopted': d['adopt'].values.astype(np.int64)\n",
    "}\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_code = dat[\"color_id\"]\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    a = pm.Normal(\"a\", mu=0, sigma=5, shape=2)\n",
    "\n",
    "    # log link\n",
    "    mu = pm.math.log(a[color_code])\n",
    "    lambda_ = 1.0 / mu\n",
    "\n",
    "    upper_bound = np.where(dat[\"adopted\"] == 1, dat[\"days_to_event\"], np.inf)\n",
    "\n",
    "    obs = pm.Censored(\n",
    "        \"obs\",\n",
    "        dist=pm.Exponential.dist(lam=lambda_),\n",
    "        lower=None,\n",
    "        upper=upper_bound, # right-censored\n",
    "        observed=dat[\"days_to_event\"]\n",
    "    )\n",
    "    \n",
    "    trace = pm.sample(\n",
    "        tune=300, \n",
    "        draws=300, \n",
    "        chains=4, \n",
    "        cores=10, \n",
    "        return_inferencedata=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace[\"posterior_predictive\"][\"obs\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bambinos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
